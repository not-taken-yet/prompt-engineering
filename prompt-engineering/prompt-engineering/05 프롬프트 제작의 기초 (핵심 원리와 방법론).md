
# 프롬프트 제작의 기초 - 핵심 원리

**토큰 (Token)**
> 자연어 처리에서 기본적으로 처리할 수 있는 언어의 '조각'이나 '단위'

프롬프트를 제작할 때는 토큰 수를 미리 예상할 수 있어야 함

**토크나이저(Tokenizer)**
- 영어에 대비해서 한국의 토큰 수는 3~4배 더 많다.
- 한국어와 같은 다른 언어를 처리할 때는 추가적인 토크나이징 과정을 거침
- 영어에서는 공백을 기준으로 단어를 구분하지만, 한국어에서는 음절, 현태소, 단어 등 다양한 기준으로 토큰화할 수 있음

**온도 (Temperature)**
> 모델에서 출력의 다양성을 조절하기 위해 사용함 

- <u>값이 높을수록</u>모델이 더 많은 선택지를 가지고 있으며, 결과적으로 더 다양한 텍스트를 생성함
- <u>낮은 온도일수록</u> 모델이 더 확신 있게 예측을 한다
	- 일반적으로 더 정확하고 일관된 텍스트를 생성함

**상위 Top P**
> 모델이 다음 단어를 선택할 때 확률이 상위 P%에 해당하는 단어들만 고려하도록 하는 것 

- 확률 분포의 상위 P%에 속하는 단어들만 후보로 선택하여 더 다양한 텍스트를 생성할 수 있음
- Temperature를 <u>매우 높게 했을 때 결과가 무너지는 것을 방지</u>하기 위해 추가로 사용 가능

**Frequency Penalty**
> 모델이 이전에 선택한 토큰이나 패턴과 비슷한 토큰을 다시 선택하는 것을 억제하는 옵션

- <u>반복되는 패턴을 피하고 다양성을 유지</u>하는 데 도움이 됨
- 이전 단어가 "사과"였을 때 모델이 다시 "사과"를 선택하지 않도록 하여 단어의 반복을 줄임

**Presence Penalty**
> 특정 토큰 또는 패턴의 등장을 억제하는 데 사용

- 모델이 특정 토큰이나 패턴을 생성하지 않도록 하여 출력의 다양성을 높이고 원하는 결과를 얻을 수 있음
- 원하지 않는 단어나 특정 패턴의 등장을 줄이는데 유용


<hr>

# 엔지니어링 기법 - Basic

## 1️⃣ Zero-Shot Prompting

<mark>예시 없이 주어진 과제를 수행하는 것</mark>

> - 언어 모델에게 <u>예제나 시연(Demonstrations)을 주지 않고 작업을 수행하는 방법</u>
> - 언어 모델이 기존 지식을 사용하여 작업을 추론함
> - 대량의 데이터를 사전 학습 했기 때문에 가능

제로샷 프롬프트는 언어 모델의 강력한 기능 중 하나
최소한의 정보만으로도 다양한 작업을 수행할 수 있음
이 기술은 특히 데이터가 부족한 상황에서 유용하게 활용됨

- **Instruction-Tuning**
- **RLHF (Reinforcement Learning form Human Feedback)**
	- 인간의 피드백을 활용하여 모델의 응답을 개선
	- ChatGPT의 학습 방법

### Example

- **Text Classification**

```
Prompt: 다음 텍스트에서 긍정, 부정, 중립 중 하나로 분류해.

텍스트: 나는 마라탕 맛이 그저 그랬어.
Sentiment:
```

- **Translation**

```
Prompt: 다음 한국어 단어를 영어로 번역해줘.

단어: 인공 눈물
```

- **Closed Question Answering**

```
Prompt: 대한민국의 수도는 서울이야?
```

## 2️⃣ Few-Shot Prompting

<mark>Few examples, 예시를 제공하여 모델이 작업을 수행하도록 유도</mark>

> 언어 모델에게 예제나 시연(Demonstration)을 주며 작업을 수행하는 방법

<i>Open AI's Research: Language Models are Few-Shot Learners (Brown et al.2020)</i>

- Few-shot prompting은 모델의 파라미터 수가 충분히 클 때 효과가 있음
- 어렵고 복잡한 과제일수록, 예제를 많이 사용하여 해결 할 수 있다.

<i>Rethinking the Role of Demonstrations: What Makes In-Context Learning Work? (2022)</i>

- <연구 결과>
	- **예시 사용**
		- 예시를 사용하면 모델의 성능을 향상 시킴
	- **예시의 품질 중요**
		- 정답 라벨(Gold labels)이 가장 좋지만, 랜덤 예시도 모델의 추론에 도움이 됨
	- **프롬프트 포맷**
		- 올바른 입력-라벨 형식을 유지하는 것이 중요
	- **멀티 초이스 작업: 라벨 형식의 중요성**
		- 입력-라벨 형식을 유지하는 것이 모델 성능을 최적화하는 데 필수적
		- 형식을 유지하면 랜덤 라벨을 사용하더라도 좋은 성능을 보일 수 있음

```
A "whatpu" is a small, furry animal native to Tanzania.
An example of a sentence that uses the word whatpu is:
We were traveling in africa and we saw these very cute whatpus.

To do a "farduddle" means to jump up and down really fast.
An example of a sentence that uses the word farduddle is:
```

```
<Random>
부정 이건 정말 굉장해!
와 정말 나쁘다! 긍정
그 영화 진짜 대박이더라.
긍정
아우 저말 끔직해~~

<Format>
이건 정말 굉장해!//부정
와 정말 나쁘다!//긍정
그 영화 진짜 대박이더라.//긍정
아우 정말 끔찍해

포맷팅을 유지하면서 예시를 주는 것이 프롬프트의 성능이 올라갔다.
```

## 3️⃣ Chain-of-Thought Prompting

<mark>모델이 단계별로 논리적인 사고 과정을 통해 답을 도출하도록 유도</mark>

> 복잡한 과제 수행을 위해, LLM에게 더 자세한 안내 문구를 작성해주는 것

- 복잡한 Task (Arithmetic, commonsense, and symbolic reasoning tasks)에 사용하면 효율적
- <u>중간 추론 단계</u>를 거치도록 하는 문장으로 구성

CoT를 사용하여 다양한 문제를 해결하는 예시?
: 산술 문제, 상식 추론, 전략적 추론, 스포츠 이해, 날짜 이해, 감정 이해 등

Chain-Of-Thought은 모델의 파라미터가 클 때 효과적이다.

**CoT의 한계점**
- 모델의 파라미터 수가 적은 모델에서는 기법의 성능이 떨어짐
- 사람이 직접 사고의 과정을 문장으로 작성해야 하는 번거로움
- 프롬프트의 완성도가 높지 않으면 결과가 좋지 않음

## 4️⃣ Zero-shot Chain-of-Thought Prompting

<mark>예시 없이도 모델이 논리적 사고 과정을 통해 문제를 해결하도록 유도</mark>

> 단계적으로 생각해봐 (Let's Think Step by Step)

## 5️⃣ Self-Consistency

> 가장 많은 답이 정답일 확률이 높다
> -> 다수결 투표 방식의 정확도가 높음

- Chain-of-thought prompting을 개선한 기법
- 다양한 추론 경로를 만들어 그 중에서 가장 일관된 답변을 선택하는 방식
- 복잡한 산술 문제나 논리 문제에 효과적

<i>Self-Consistency Improves Chain-of-Thought Reasoning in Language Models (2022)</i>

- 문제에 대한 여러 추론 경로를 고려하면서, 단일 추론이 갖고 있는 오류 가능성을 줄임
- 수학 문제와 같이 정확성을 요구하는 일에서 모델 답변의 정확성을 높일 수 있음

**Self-Consistency의 한계점**
- 복잡한 추론 작업을 해결 할 때 비용이 많이 듦
- 복잡한 추론을 해결하려면, 상당한 양의 훈련 데이터 필요. 모델이 일관된 응답을 효과적으로 생성하기 위해 다양한 추론 패턴을 학습해야 하기 때문
- 프롬프트가 명확하지 않거나 간결하지 않을 때, Self-Consistency의 기법 성능이 저하됨

<hr>

# 엔지니어링 기법 - Advanced

## 1️⃣ Generate Knowledge Prompting

> 모델로부터 최종 답변을 얻기 전 모델이 직접 관련 정보를 가져오도록 한 다음 이를 활용해서 답을 가져오도록 하는 방식

- **개요**: 연어 모델의 추론 능력을 더 향상시키기 위한 방법
- **목적**:
	- 할루시네이션 현상을 완화하기 위한 방법
	- 언어 모델이 추가 지식을 활용하게 하는 것
	- 언어 모델이 오픈 Q-A 태스크 방식을 활용하여 스스로 지식을 생성함

1. 지식 생성 
2. 지식 통합
3. 답변 생성

## 2️⃣ Prompt Chaining

> 복잡한 작업을 더 작고 관리하기 쉬운 하위 작업을 나누어 각각의 하위 작업을 별도의 프롬프트로 처리하는 기법

- 한 프롬프트의 출력이 다음 프롬프트의 입력으로 사용
- 대형 언어 모델(LLM)의 성능과 신뢰성을 향상시키고 투명성, 제어 가능성, 신뢰성을 높임

1. 다단계 작업
2. 복잡한 지시사항
3. 출력물 검증
4. 병렬 처리

## 3️⃣ Tree of Thought

> 더 복잡하고, 전략적인 과제 해결을 위한 프레임워크

- CoT 프롬프트를 일반화하고, 언어 모델을 사용한 일반 문제 해결을 위해 중간 단계를 거치며 탐색
- 문제를 해결하기 위해 여러 가능성을 탐색하며 최적의 해결책을 찾아감

1. 생각 분해하기
2. 생각 생성하기
3. 생각 평가하기
4. 검색 알고리즘

> ToT 방식 + RAG를 사용하면 hallucination을 낮추는 효과가 있다.

### CoT vs ToT

- CoT는 회귀를 할 수 없다.
	- 언어 모델에 입력 값을 넣으면 순차적으로 진행하면서 추론한 결과를 내놓는다.
- ToT는 중간에 회귀를 하고 더 좋은 방법을 시도한다.

